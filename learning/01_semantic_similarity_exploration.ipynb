{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity Exploration\n",
    "\n",
    "This notebook explores how YT Study Buddy uses semantic similarity for auto-categorization and improved cross-referencing.\n",
    "\n",
    "## Learning Goals:\n",
    "- Understand sentence transformers and embedding models\n",
    "- Experiment with semantic similarity calculations\n",
    "- Compare different similarity metrics\n",
    "- Find optimal thresholds for YouTube content categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "# !pip install sentence-transformers scikit-learn matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Comparing Different Models\n",
    "\n",
    "Let's explore different sentence transformer models and their characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load different models for comparison\n",
    "models = {\n",
    "    'MiniLM': 'all-MiniLM-L6-v2',  # Fast, good quality (default in YT Study Buddy)\n",
    "    'MPNet': 'all-mpnet-base-v2',   # Higher quality, slower\n",
    "    'Distilbert': 'all-distilroberta-v1'  # Alternative architecture\n",
    "}\n",
    "\n",
    "loaded_models = {}\n",
    "for name, model_name in models.items():\n",
    "    print(f\"Loading {name} ({model_name})...\")\n",
    "    loaded_models[name] = SentenceTransformer(model_name)\n",
    "    print(f\"  Embedding dimension: {loaded_models[name].get_sentence_embedding_dimension()}\")\n",
    "\n",
    "print(\"\\nAll models loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample YouTube Video Content\n",
    "\n",
    "Let's create sample content that represents different subjects YT Study Buddy might encounter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample video content from different subjects\n",
    "sample_content = {\n",
    "    'Machine Learning': [\n",
    "        \"Understanding neural networks and deep learning algorithms\",\n",
    "        \"Training models with backpropagation and gradient descent\",\n",
    "        \"Transformer architecture and attention mechanisms\",\n",
    "        \"Computer vision with convolutional neural networks\"\n",
    "    ],\n",
    "    'Web Development': [\n",
    "        \"Building React applications with modern JavaScript\",\n",
    "        \"Creating RESTful APIs with Node.js and Express\",\n",
    "        \"CSS Grid and Flexbox for responsive design\",\n",
    "        \"Database design with PostgreSQL and MongoDB\"\n",
    "    ],\n",
    "    'Data Science': [\n",
    "        \"Exploratory data analysis with pandas and matplotlib\",\n",
    "        \"Statistical modeling and hypothesis testing\",\n",
    "        \"Data visualization techniques and best practices\",\n",
    "        \"Time series forecasting and trend analysis\"\n",
    "    ],\n",
    "    'Physics': [\n",
    "        \"Quantum mechanics and wave-particle duality\",\n",
    "        \"Thermodynamics and statistical mechanics\",\n",
    "        \"Electromagnetic theory and Maxwell's equations\",\n",
    "        \"Relativity theory and spacetime curvature\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Flatten for easier processing\n",
    "all_content = []\n",
    "content_labels = []\n",
    "for subject, descriptions in sample_content.items():\n",
    "    all_content.extend(descriptions)\n",
    "    content_labels.extend([subject] * len(descriptions))\n",
    "\n",
    "print(f\"Sample content: {len(all_content)} descriptions across {len(sample_content)} subjects\")\n",
    "for subject, descriptions in sample_content.items():\n",
    "    print(f\"  {subject}: {len(descriptions)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encoding Content and Calculating Similarities\n",
    "\n",
    "Let's encode our sample content using different models and compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode content with each model\n",
    "embeddings = {}\n",
    "for model_name, model in loaded_models.items():\n",
    "    print(f\"Encoding content with {model_name}...\")\n",
    "    embeddings[model_name] = model.encode(all_content)\n",
    "    print(f\"  Shape: {embeddings[model_name].shape}\")\n",
    "\n",
    "print(\"\\nEncoding complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity matrices for each model\n",
    "similarities = {}\n",
    "for model_name, emb in embeddings.items():\n",
    "    similarities[model_name] = cosine_similarity(emb)\n",
    "\n",
    "# Visualize similarity matrices\n",
    "fig, axes = plt.subplots(1, len(loaded_models), figsize=(15, 4))\n",
    "if len(loaded_models) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (model_name, sim_matrix) in enumerate(similarities.items()):\n",
    "    im = axes[i].imshow(sim_matrix, cmap='viridis', vmin=0, vmax=1)\n",
    "    axes[i].set_title(f'{model_name} Similarity Matrix')\n",
    "    axes[i].set_xlabel('Content Index')\n",
    "    axes[i].set_ylabel('Content Index')\n",
    "    \n",
    "plt.colorbar(im, ax=axes, shrink=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Darker areas indicate higher similarity between content pieces.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Threshold Analysis\n",
    "\n",
    "Let's find optimal similarity thresholds for categorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_thresholds(similarity_matrix, labels, thresholds=np.arange(0.1, 1.0, 0.05)):\n",
    "    \"\"\"Analyze categorization accuracy at different similarity thresholds.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        correct_matches = 0\n",
    "        total_matches = 0\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            for j in range(i + 1, len(labels)):\n",
    "                sim_score = similarity_matrix[i, j]\n",
    "                \n",
    "                if sim_score > threshold:\n",
    "                    total_matches += 1\n",
    "                    if labels[i] == labels[j]:  # Same subject\n",
    "                        correct_matches += 1\n",
    "        \n",
    "        precision = correct_matches / total_matches if total_matches > 0 else 0\n",
    "        results.append((threshold, precision, total_matches))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyze thresholds for each model\n",
    "threshold_results = {}\n",
    "for model_name, sim_matrix in similarities.items():\n",
    "    threshold_results[model_name] = analyze_thresholds(sim_matrix, content_labels)\n",
    "\n",
    "# Plot threshold analysis\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for model_name, results in threshold_results.items():\n",
    "    thresholds, precisions, match_counts = zip(*results)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(thresholds, precisions, marker='o', label=f'{model_name} Precision')\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(thresholds, match_counts, marker='s', label=f'{model_name} Total Matches')\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.xlabel('Similarity Threshold')\n",
    "plt.ylabel('Precision (Correct/Total)')\n",
    "plt.title('Categorization Precision vs Similarity Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.xlabel('Similarity Threshold')\n",
    "plt.ylabel('Number of Matches')\n",
    "plt.title('Total Matches vs Similarity Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization with t-SNE\n",
    "\n",
    "Let's visualize how well the embeddings cluster similar content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create t-SNE visualization for each model\n",
    "fig, axes = plt.subplots(1, len(loaded_models), figsize=(5 * len(loaded_models), 4))\n",
    "if len(loaded_models) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']\n",
    "subject_to_color = {subject: colors[i] for i, subject in enumerate(sample_content.keys())}\n",
    "\n",
    "for i, (model_name, emb) in enumerate(embeddings.items()):\n",
    "    # Apply t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(all_content)-1))\n",
    "    embedded = tsne.fit_transform(emb)\n",
    "    \n",
    "    # Plot each subject with different colors\n",
    "    for subject in sample_content.keys():\n",
    "        mask = [label == subject for label in content_labels]\n",
    "        axes[i].scatter(embedded[mask, 0], embedded[mask, 1], \n",
    "                       c=subject_to_color[subject], label=subject, alpha=0.7, s=60)\n",
    "    \n",
    "    axes[i].set_title(f'{model_name} t-SNE Visualization')\n",
    "    axes[i].set_xlabel('t-SNE Dimension 1')\n",
    "    axes[i].set_ylabel('t-SNE Dimension 2')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Good clustering means similar subjects are grouped together visually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Real-World Testing\n",
    "\n",
    "Let's test with actual YouTube video titles and see how well our categorization works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real YouTube video titles for testing\n",
    "real_videos = [\n",
    "    \"Building a Neural Network from Scratch in Python\",\n",
    "    \"React Hooks Tutorial - useState and useEffect\",\n",
    "    \"Introduction to Quantum Computing\",\n",
    "    \"Data Analysis with Pandas - Complete Guide\",\n",
    "    \"Understanding Transformers in NLP\",\n",
    "    \"CSS Grid Layout Tutorial\",\n",
    "    \"Statistical Significance and P-Values\",\n",
    "    \"Einstein's Theory of General Relativity\",\n",
    "    \"Machine Learning Model Deployment\",\n",
    "    \"JavaScript Async/Await Explained\"\n",
    "]\n",
    "\n",
    "# Expected categories\n",
    "expected_categories = [\n",
    "    \"Machine Learning\", \"Web Development\", \"Physics\", \"Data Science\",\n",
    "    \"Machine Learning\", \"Web Development\", \"Data Science\", \"Physics\",\n",
    "    \"Machine Learning\", \"Web Development\"\n",
    "]\n",
    "\n",
    "# Test auto-categorization\n",
    "def test_categorization(video_titles, existing_subjects, model, threshold=0.6):\n",
    "    \"\"\"Test how well the model categorizes new video titles.\"\"\"\n",
    "    # Encode existing subjects and new titles\n",
    "    subject_embeddings = model.encode(list(existing_subjects.keys()))\n",
    "    title_embeddings = model.encode(video_titles)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity(title_embeddings, subject_embeddings)\n",
    "    \n",
    "    results = []\n",
    "    for i, title in enumerate(video_titles):\n",
    "        best_match_idx = np.argmax(similarities[i])\n",
    "        best_score = similarities[i][best_match_idx]\n",
    "        \n",
    "        if best_score > threshold:\n",
    "            predicted_subject = list(existing_subjects.keys())[best_match_idx]\n",
    "        else:\n",
    "            predicted_subject = \"New Subject\"\n",
    "        \n",
    "        results.append({\n",
    "            'title': title,\n",
    "            'predicted': predicted_subject,\n",
    "            'confidence': best_score,\n",
    "            'expected': expected_categories[i]\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test with MiniLM model (default in YT Study Buddy)\n",
    "model = loaded_models['MiniLM']\n",
    "categorization_results = test_categorization(real_videos, sample_content, model)\n",
    "\n",
    "# Display results\n",
    "print(\"Auto-Categorization Results:\")\n",
    "print(\"=\" * 80)\n",
    "correct = 0\n",
    "\n",
    "for result in categorization_results:\n",
    "    is_correct = result['predicted'] == result['expected']\n",
    "    if is_correct:\n",
    "        correct += 1\n",
    "    \n",
    "    status = \"âœ“\" if is_correct else \"âœ—\"\n",
    "    print(f\"{status} {result['title'][:50]:<50} | {result['predicted']:<15} | {result['confidence']:.3f}\")\n",
    "\n",
    "accuracy = correct / len(categorization_results)\n",
    "print(\"=\" * 80)\n",
    "print(f\"Accuracy: {accuracy:.1%} ({correct}/{len(categorization_results)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Comparison\n",
    "\n",
    "Let's compare the performance and speed of different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Performance testing\n",
    "test_texts = real_videos * 10  # 100 texts for speed testing\n",
    "\n",
    "performance_results = {}\n",
    "for model_name, model in loaded_models.items():\n",
    "    # Time the encoding\n",
    "    start_time = time.time()\n",
    "    embeddings_test = model.encode(test_texts)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    encoding_time = end_time - start_time\n",
    "    texts_per_second = len(test_texts) / encoding_time\n",
    "    \n",
    "    performance_results[model_name] = {\n",
    "        'encoding_time': encoding_time,\n",
    "        'texts_per_second': texts_per_second,\n",
    "        'embedding_dim': model.get_sentence_embedding_dimension()\n",
    "    }\n",
    "\n",
    "# Display performance comparison\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<15} {'Time (s)':<10} {'Texts/sec':<10} {'Embed Dim':<10}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for model_name, perf in performance_results.items():\n",
    "    print(f\"{model_name:<15} {perf['encoding_time']:<10.2f} {perf['texts_per_second']:<10.1f} {perf['embedding_dim']:<10}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Key Insights:\")\n",
    "print(\"- MiniLM is fastest and works well for YT Study Buddy's use case\")\n",
    "print(\"- MPNet provides highest quality but is slower\")\n",
    "print(\"- Higher embedding dimensions generally mean better representation\")\n",
    "print(\"- Choose based on your speed vs. accuracy requirements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Experimentation Section\n",
    "\n",
    "Try your own experiments here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§ª Experiment: Try your own video titles\n",
    "your_video_titles = [\n",
    "    \"Add your own YouTube video titles here\",\n",
    "    \"Test how well the categorization works\",\n",
    "    \"Experiment with different subjects\"\n",
    "]\n",
    "\n",
    "# Test with your titles\n",
    "if your_video_titles[0] != \"Add your own YouTube video titles here\":\n",
    "    your_results = test_categorization(your_video_titles, sample_content, loaded_models['MiniLM'])\n",
    "    \n",
    "    print(\"Your Categorization Results:\")\n",
    "    for result in your_results:\n",
    "        print(f\"{result['title'][:50]:<50} | {result['predicted']:<15} | {result['confidence']:.3f}\")\n",
    "else:\n",
    "    print(\"Replace the sample titles above with your own to test categorization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§ª Experiment: Try different similarity metrics\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Compare cosine vs euclidean distance\n",
    "sample_embeddings = loaded_models['MiniLM'].encode([\"Machine learning tutorial\", \"Deep learning basics\", \"Web development guide\"])\n",
    "\n",
    "cosine_sim = cosine_similarity(sample_embeddings)\n",
    "euclidean_dist = squareform(pdist(sample_embeddings, metric='euclidean'))\n",
    "\n",
    "print(\"Cosine Similarity:\")\n",
    "print(cosine_sim)\n",
    "print(\"\\nEuclidean Distance:\")\n",
    "print(euclidean_dist)\n",
    "\n",
    "print(\"\\nðŸ’¡ Note: Lower euclidean distance = higher similarity\")\n",
    "print(\"ðŸ’¡ Note: Higher cosine similarity = higher similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Key Takeaways\n",
    "\n",
    "1. **Model Choice**: MiniLM provides the best speed/accuracy tradeoff for YT Study Buddy\n",
    "2. **Threshold Selection**: ~0.6 cosine similarity works well for categorization\n",
    "3. **Semantic Understanding**: Embeddings capture meaning better than keyword matching\n",
    "4. **Visualization**: t-SNE helps validate that similar content clusters together\n",
    "5. **Performance**: Consider encoding speed for real-time applications\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "- Experiment with fine-tuning models on your specific domain\n",
    "- Try different similarity thresholds based on your content\n",
    "- Explore multi-modal embeddings (text + other features)\n",
    "- Implement vector databases for large-scale similarity search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}