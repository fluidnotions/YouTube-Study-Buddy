@startuml YT Study Buddy Architecture

!define RECTANGLE class

skinparam backgroundColor #FEFEFE
skinparam classAttributeIconSize 0
skinparam classFontStyle bold

title YT Study Buddy - System Architecture

package "CLI Interface" {
    class YouTubeStudyNotes {
        - subject: Optional[str]
        - global_context: bool
        - base_dir: str
        - output_dir: str
        - generate_assessments: bool
        - auto_categorize: bool
        - parallel: bool
        - max_workers: int
        - _file_lock: threading.Lock
        - _kg_lock: threading.Lock
        --
        + __init__(subject, global_context, base_dir, generate_assessments, auto_categorize, parallel, max_workers)
        + read_urls_from_file(filename): List[str]
        + process_single_url(url, worker_processor): ProcessingResult
        + process_urls(urls): void
    }

    class CLI {
        + main(): void
        + show_help(): void
    }
}

package "Core Processing" {
    class VideoProcessor {
        - provider: TranscriptProvider
        - provider_type: str
        --
        + __init__(provider_type, **kwargs)
        + get_video_id(url): Optional[str]
        + get_video_title(video_id): str
        + get_transcript(video_id): dict
        + sanitize_filename(filename): str
    }

    class ParallelVideoProcessor {
        - max_workers: int
        - rate_limit_delay: float
        - progress_callback: Optional[Callable]
        --
        + __init__(max_workers, rate_limit_delay, progress_callback)
        + process_videos_parallel(urls, process_func, worker_factory): List[ProcessingResult]
    }

    class ProcessingResult <<dataclass>> {
        + url: str
        + video_id: str
        + success: bool
        + title: Optional[str]
        + filepath: Optional[str]
        + error: Optional[str]
        + duration_seconds: float
        + method: Optional[str]
    }

    class ProcessingMetrics {
        - total_videos: int
        - successful: int
        - failed: int
        - total_time: float
        - method_counts: Dict[str, int]
        --
        + add_result(result): void
        + print_summary(): void
    }
}

package "Transcript Fetching" {
    interface TranscriptProvider <<Protocol>> {
        + get_transcript(video_id): Dict[str, Any]
        + get_video_title(video_id): str
    }

    abstract class AbstractTranscriptProvider {
        {abstract} + get_transcript(video_id): Dict[str, Any]
        {abstract} + get_video_title(video_id): str
        + get_video_id(url): Optional[str]
    }

    class TorTranscriptProvider {
        - tor_fetcher: TorTranscriptFetcher
        - use_tor_first: bool
        - _tor_verified: bool
        - stats: Dict[str, int]
        --
        + __init__(tor_host, tor_port, use_tor_first)
        + verify_tor_connection(): bool
        + get_transcript(video_id): Dict[str, Any]
        + get_video_title(video_id): str
        - _retry_with_backoff(video_id, max_retries): Dict[str, Any]
        + print_stats(): void
    }

    class TorTranscriptFetcher {
        - tor_host: str
        - tor_port: int
        --
        + fetch_with_fallback(video_id, use_tor_first, languages): Dict[str, Any]
        + get_video_title(video_id): str
        + check_tor_connection(): bool
    }

    note right of TorTranscriptFetcher
        Handles low-level Tor proxy
        communication and yt-dlp fallback
    end note
}

package "AI Content Generation" {
    class StudyNotesGenerator {
        - client: anthropic.Anthropic
        --
        + __init__()
        - _setup_api(): void
        + get_api_key(): Optional[str]
        + is_ready(): bool
        + generate_notes(transcript, related_notes): str
        - _build_prompt(transcript, related_notes): str
        + extract_title_from_notes(study_notes): Optional[str]
        + create_markdown_file(title, video_url, study_notes, output_dir, video_id): str
    }

    class AssessmentGenerator {
        - claude_client: anthropic.Anthropic
        --
        + __init__(claude_client)
        + generate_assessment(transcript, notes_content, video_title, video_url): str
        - _generate_questions(transcript, notes_content, video_title): Dict
        - _extract_json_from_response(response_text): Optional[Dict]
        - _create_fallback_questions(video_title): Dict
        - _format_assessment_file(questions_data, video_title, video_url): str
        - _get_category_title(category): str
        - _create_fallback_assessment(video_title, video_url): str
        + create_assessment_filename(video_title): str
    }

    note right of AssessmentGenerator
        Generates:
        - Gap Analysis Questions
        - Application Questions
        - One-Up Challenges
        - Synthesis Questions
    end note
}

package "Content Organization" {
    class AutoCategorizer {
        - model_name: str
        - model: Optional[SentenceTransformer]
        - _similarity_threshold: float
        --
        + __init__(model_name)
        - _load_model(): bool
        + categorize_video(transcript, video_title, output_dir, subject): str
        - _get_existing_subjects(output_dir): List[str]
        - _find_semantic_match(transcript, video_title, existing_subjects): Optional[str]
        - _find_keyword_match(transcript, video_title, existing_subjects): Optional[str]
        - _extract_subject_from_content(transcript, video_title): str
        + get_categorization_info(): dict
    }

    class KnowledgeGraph {
        - base_dir: str
        - subject: Optional[str]
        - global_context: bool
        - subject_dir: str
        - _concepts_cache: Optional[Dict]
        - _global_cache: Optional[Dict]
        --
        + __init__(base_dir, subject, global_context)
        + extract_concepts_from_notes(force_refresh, global_scope): Dict
        - _extract_concepts_from_content(content): Set[str]
        - _extract_from_section(section_text): Set[str]
        - _extract_definitions(defs_text): Set[str]
        - _extract_key_phrases(key_text): Set[str]
        + find_related_notes(current_transcript, global_scope): List[Dict]
        + refresh_cache(): Dict
        + get_stats(global_scope): Dict
    }

    class ObsidianLinker {
        - base_dir: str
        - subject: Optional[str]
        - global_context: bool
        - min_similarity: int
        - note_titles: Dict
        --
        + __init__(base_dir, subject, global_context, min_similarity)
        + build_note_index(): void
        + extract_existing_links(content): Set[str]
        + find_potential_links(content, exclude_current_title): List[Dict]
        - _extract_phrases(sentence): List[str]
        - _is_valid_link(phrase, title, context): bool
        + apply_links(content, file_path, current_title): str
        + process_file(file_path): bool
        + get_stats(): Dict
    }

    note right of ObsidianLinker
        Uses fuzzy matching
        to create [[Wiki-style]]
        links between notes
    end note
}

package "External Dependencies" {
    class Claude_API <<external>> {
        + messages.create()
    }

    class Tor_Proxy <<external>> {
        + SOCKS5 Proxy
        + Port 9050
    }

    class SentenceTransformer <<external>> {
        + encode()
    }
}

' Relationships - CLI
CLI --> YouTubeStudyNotes : creates
YouTubeStudyNotes --> VideoProcessor : uses
YouTubeStudyNotes --> ParallelVideoProcessor : uses (optional)
YouTubeStudyNotes --> StudyNotesGenerator : uses
YouTubeStudyNotes --> AssessmentGenerator : uses (optional)
YouTubeStudyNotes --> AutoCategorizer : uses (optional)
YouTubeStudyNotes --> KnowledgeGraph : uses
YouTubeStudyNotes --> ObsidianLinker : uses

' Relationships - Processing
VideoProcessor --> TranscriptProvider : uses
ParallelVideoProcessor --> ProcessingResult : creates
ParallelVideoProcessor --> ProcessingMetrics : uses
ParallelVideoProcessor --> VideoProcessor : creates workers

' Relationships - Transcript Fetching
TorTranscriptProvider ..|> TranscriptProvider : implements
TorTranscriptProvider --|> AbstractTranscriptProvider : extends
TorTranscriptProvider --> TorTranscriptFetcher : uses
TorTranscriptFetcher --> Tor_Proxy : connects to

' Relationships - AI Generation
StudyNotesGenerator --> Claude_API : calls
AssessmentGenerator --> Claude_API : calls
StudyNotesGenerator --> KnowledgeGraph : gets related notes from

' Relationships - Content Organization
AutoCategorizer --> SentenceTransformer : uses
KnowledgeGraph --> ObsidianLinker : provides concepts to

' Data Flow
note as DataFlow
    **Main Processing Flow:**
    1. CLI receives YouTube URLs
    2. VideoProcessor extracts video ID
    3. TorTranscriptProvider fetches transcript via Tor
    4. AutoCategorizer determines subject (optional)
    5. StudyNotesGenerator creates notes with Claude
    6. AssessmentGenerator creates questions (optional)
    7. KnowledgeGraph indexes concepts
    8. ObsidianLinker adds cross-references
    9. Markdown files saved to disk
end note

@enduml
